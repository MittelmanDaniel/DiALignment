{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.163416Z",
     "start_time": "2024-10-27T00:55:47.921669Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\henry\\anaconda3\\envs\\dialignment\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import functools\n",
    "import einops\n",
    "import requests\n",
    "import pandas as pd\n",
    "import io\n",
    "import textwrap\n",
    "import gc\n",
    "import numpy as np\n",
    "\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torch import Tensor\n",
    "from typing import List, Callable\n",
    "from transformer_lens import HookedTransformer, utils\n",
    "from transformer_lens.hook_points import HookPoint\n",
    "from transformers import AutoTokenizer\n",
    "from jaxtyping import Float, Int\n",
    "from colorama import Fore\n",
    "\n",
    "from prompt_gen import generate_prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d985625279bccd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.218660Z",
     "start_time": "2024-10-27T00:55:56.201534Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49655b1fbbf3135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.327180Z",
     "start_time": "2024-10-27T00:55:56.312934Z"
    }
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "575181eb0b857e73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.342367Z",
     "start_time": "2024-10-27T00:55:56.337350Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_name: str) -> HookedTransformer:\n",
    "    model = HookedTransformer.from_pretrained_no_processing(\n",
    "      model_name,\n",
    "      device=DEVICE,\n",
    "      dtype=torch.float16,\n",
    "    )\n",
    "    \n",
    "    model.tokenizer.padding_side = 'left'\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a73fa97f54f976fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.404294Z",
     "start_time": "2024-10-27T00:55:56.386887Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_harmful_instructions():\n",
    "    url = 'https://raw.githubusercontent.com/llm-attacks/llm-attacks/main/data/advbench/harmful_behaviors.csv'\n",
    "    response = requests.get(url)\n",
    "\n",
    "    dataset = pd.read_csv(io.StringIO(response.content.decode('utf-8')))\n",
    "    instructions = dataset['goal'].tolist()\n",
    "\n",
    "    train, test = train_test_split(instructions, test_size=0.2, random_state=42)\n",
    "    return train, test\n",
    "\n",
    "def get_harmless_instructions():\n",
    "    hf_path = 'tatsu-lab/alpaca'\n",
    "    dataset = load_dataset(hf_path)\n",
    "\n",
    "    # filter for instructions that do not have inputs\n",
    "    instructions = []\n",
    "    for i in range(len(dataset['train'])):\n",
    "        if dataset['train'][i]['input'].strip() == '':\n",
    "            instructions.append(dataset['train'][i]['instruction'])\n",
    "\n",
    "    train, test = train_test_split(instructions, test_size=0.2, random_state=42)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9794d948ab7dc0ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.450471Z",
     "start_time": "2024-10-27T00:55:56.441274Z"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(model, instructions):\n",
    "    chat = [\n",
    "        {\"role\": \"user\", \"content\": instructions}\n",
    "    ]\n",
    "    text_tokens = model.tokenizer.apply_chat_template(chat, tokenize=False, padding=True, truncation=True)\n",
    "    tokens = model.tokenizer.apply_chat_template(chat, tokenize=True, padding=\"max_length\", max_length=128, truncation=True, return_tensors=\"pt\")\n",
    "    print(tokens.shape)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5e9adcd13aaf4c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.497157Z",
     "start_time": "2024-10-27T00:55:56.474476Z"
    }
   },
   "outputs": [],
   "source": [
    "def _generate_with_hooks(\n",
    "    model: HookedTransformer,\n",
    "    toks: Int[Tensor, 'batch_size seq_len'],\n",
    "    max_tokens_generated: int = 64,\n",
    "    fwd_hooks = [],\n",
    ") -> List[str]:\n",
    "\n",
    "    all_toks = torch.zeros((toks.shape[0], toks.shape[1] + max_tokens_generated), dtype=torch.long, device=toks.device)\n",
    "    all_toks[:, :toks.shape[1]] = toks\n",
    "\n",
    "    for i in range(max_tokens_generated):\n",
    "        with model.hooks(fwd_hooks=fwd_hooks):\n",
    "            logits = model(all_toks[:, :-max_tokens_generated + i])\n",
    "            next_tokens = logits[:, -1, :].argmax(dim=-1) # greedy sampling (temperature=0)\n",
    "            all_toks[:,-max_tokens_generated+i] = next_tokens\n",
    "\n",
    "    return model.tokenizer.batch_decode(all_toks[:, toks.shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "def get_generations(\n",
    "    model: HookedTransformer,\n",
    "    instructions: List[str],\n",
    "    tokenize_instructions_fn,\n",
    "    fwd_hooks = [],\n",
    "    max_tokens_generated: int = 64,\n",
    "    batch_size=4\n",
    ") -> List[str]:\n",
    "\n",
    "    generations = []\n",
    "    \n",
    "    raw_toks = [tokenize_instructions_fn(instructions=instruction) for instruction in instructions]\n",
    "    print(raw_toks)\n",
    "    all_toks = torch.Tensor(raw_toks, device=DEVICE)\n",
    "\n",
    "    for i in tqdm(range(0, len(instructions), batch_size)):\n",
    "        \n",
    "        generation = _generate_with_hooks(\n",
    "            model,\n",
    "            all_toks[i:i+batch_size],\n",
    "            max_tokens_generated=max_tokens_generated,\n",
    "            fwd_hooks=fwd_hooks,\n",
    "        )\n",
    "        generations.extend(generation)\n",
    "\n",
    "    return generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71734f0b1c606ef0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.557934Z",
     "start_time": "2024-10-27T00:55:56.549795Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_mean_activation(model, tokenizer, prompts, batch_size):\n",
    "    n_samples = len(prompts)\n",
    "    n_layers = model.cfg.n_layers\n",
    "    pos = -1\n",
    "    \n",
    "    mean_act = torch.zeros((n_layers, 1, model.cfg.d_model), dtype=model.cfg.dtype, device=DEVICE)\n",
    "    \n",
    "    all_toks = torch.cat([tokenizer(instructions=prompt) for prompt in prompts]).to(DEVICE)\n",
    "        \n",
    "    for i in range(0, n_samples, batch_size):\n",
    "        logits, cache = model.run_with_cache(all_toks[i:i+batch_size], names_filter=lambda hook_name: 'resid' in hook_name)\n",
    "        \n",
    "        for layer_i in range(n_layers):\n",
    "            mean_act[layer_i] += cache['resid_pre', layer_i][:, pos, :].sum(dim=0) / n_samples\n",
    "            \n",
    "        # memory management\n",
    "        del cache, logits\n",
    "        gc.collect(); torch.cuda.empty_cache()\n",
    "\n",
    "    return mean_act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "912c9dc635c1f11c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.635739Z",
     "start_time": "2024-10-27T00:55:56.622560Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_activation_dir(desired_act, harmless_act):\n",
    "    delta_dir = desired_act - harmless_act\n",
    "    return delta_dir / delta_dir.norm(keepdim=True, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff18afecf81925c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.651846Z",
     "start_time": "2024-10-27T00:55:56.645802Z"
    }
   },
   "outputs": [],
   "source": [
    "def direction_ablation_hook(\n",
    "    activation: Float[Tensor, \"... d_act\"],\n",
    "    hook: HookPoint,\n",
    "    direction: Float[Tensor, \"d_act\"]\n",
    "):\n",
    "    proj = einops.einsum(activation, direction.view(-1, 1), '... d_act, d_act single -> ... single') * direction\n",
    "    return activation - proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e79650941f51ac90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.698454Z",
     "start_time": "2024-10-27T00:55:56.680221Z"
    }
   },
   "outputs": [],
   "source": [
    "def direction_amplify_hook(\n",
    "    activation: Float[Tensor, \"... d_act\"],\n",
    "    hook: HookPoint,\n",
    "    direction: Float[Tensor, \"d_act\"]\n",
    "):\n",
    "    #proj = einops.einsum(activation, direction.view(-1, 1), '... d_act, d_act single -> ... single') * direction\n",
    "    return activation + direction#proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e40d749d5d90e126",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:55:56.745453Z",
     "start_time": "2024-10-27T00:55:56.726269Z"
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(model, tokenizer, hook, intervention_direction, baseline_prompts, direction_layer=None):\n",
    "    intervention_layers = list(range(1, model.cfg.n_layers))\n",
    "    if direction_layer is None:\n",
    "        fwd_hooks = [(utils.get_act_name(act_name, l), functools.partial(hook, direction=intervention_direction[l])) for l in intervention_layers for act_name in ['resid_pre']]\n",
    "    else:\n",
    "        fwd_hooks = [(utils.get_act_name(act_name, l), functools.partial(hook, direction=intervention_direction[direction_layer])) for l in intervention_layers for act_name in ['resid_pre']]\n",
    "\n",
    "    intervention_generations = get_generations(model, baseline_prompts, tokenizer, fwd_hooks=fwd_hooks)\n",
    "    baseline_generations = get_generations(model, baseline_prompts, tokenizer, fwd_hooks=[])\n",
    "    \n",
    "    for i in range(len(baseline_prompts)):\n",
    "        print(f\"INSTRUCTION {i}: {repr(baseline_prompts[i])}\")\n",
    "        print(Fore.GREEN + f\"BASELINE COMPLETION:\")\n",
    "        print(textwrap.fill(repr(baseline_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "        print(Fore.RED + f\"INTERVENTION COMPLETION:\")\n",
    "        print(textwrap.fill(repr(intervention_generations[i]), width=100, initial_indent='\\t', subsequent_indent='\\t'))\n",
    "        print(Fore.RESET)\n",
    "        \n",
    "    return intervention_generations, baseline_generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a75c36ab76746d95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:56:34.601344Z",
     "start_time": "2024-10-27T00:55:56.771657Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model meta-llama/Llama-3.2-3B-Instruct into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"meta-llama/Llama-3.2-3B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b77cce4487825b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:56:38.755862Z",
     "start_time": "2024-10-27T00:56:34.681437Z"
    }
   },
   "outputs": [],
   "source": [
    "harmful_inst_train, harmful_inst_test = get_harmful_instructions()\n",
    "harmless_inst_train, harmless_inst_test = get_harmless_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "640899c0339d94b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:58:11.601010Z",
     "start_time": "2024-10-27T00:57:05.072015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m n_inst_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(tokenize, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m----> 5\u001b[0m harmful_mean_act \u001b[38;5;241m=\u001b[39m \u001b[43msample_mean_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mharmful_inst_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m harmless_mean_act \u001b[38;5;241m=\u001b[39m sample_mean_activation(model, tokenizer, harmless_inst_train[:n_samples], batch_size)\n",
      "Cell \u001b[1;32mIn [8], line 11\u001b[0m, in \u001b[0;36msample_mean_activation\u001b[1;34m(model, tokenizer, prompts, batch_size)\u001b[0m\n\u001b[0;32m      8\u001b[0m all_toks \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([tokenizer(instructions\u001b[38;5;241m=\u001b[39mprompt) \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts])\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, n_samples, batch_size):\n\u001b[1;32m---> 11\u001b[0m     logits, cache \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_toks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresid\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_layers):\n\u001b[0;32m     14\u001b[0m         mean_act[layer_i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m cache[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresid_pre\u001b[39m\u001b[38;5;124m'\u001b[39m, layer_i][:, pos, :]\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m/\u001b[39m n_samples\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:655\u001b[0m, in \u001b[0;36mHookedTransformer.run_with_cache\u001b[1;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_cache\u001b[39m(\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mmodel_args, return_cache_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    640\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    647\u001b[0m     Union[ActivationCache, Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[0;32m    648\u001b[0m ]:\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;124;03m\"\"\"Wrapper around `run_with_cache` in HookedRootModule.\u001b[39;00m\n\u001b[0;32m    650\u001b[0m \n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m    If return_cache_object is True, this will return an ActivationCache object, with a bunch of\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;124;03m    useful HookedTransformer specific methods, otherwise it will return a dictionary of\u001b[39;00m\n\u001b[0;32m    653\u001b[0m \u001b[38;5;124;03m    activations as in HookedRootModule.\u001b[39;00m\n\u001b[0;32m    654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 655\u001b[0m     out, cache_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrun_with_cache(\n\u001b[0;32m    656\u001b[0m         \u001b[38;5;241m*\u001b[39mmodel_args, remove_batch_dim\u001b[38;5;241m=\u001b[39mremove_batch_dim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    657\u001b[0m     )\n\u001b[0;32m    658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_cache_object:\n\u001b[0;32m    659\u001b[0m         cache \u001b[38;5;241m=\u001b[39m ActivationCache(cache_dict, \u001b[38;5;28mself\u001b[39m, has_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m remove_batch_dim)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\transformer_lens\\hook_points.py:566\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_cache\u001b[1;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[0m\n\u001b[0;32m    552\u001b[0m cache_dict, fwd, bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_caching_hooks(\n\u001b[0;32m    553\u001b[0m     names_filter,\n\u001b[0;32m    554\u001b[0m     incl_bwd,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m     pos_slice\u001b[38;5;241m=\u001b[39mpos_slice,\n\u001b[0;32m    558\u001b[0m )\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[0;32m    561\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39mfwd,\n\u001b[0;32m    562\u001b[0m     bwd_hooks\u001b[38;5;241m=\u001b[39mbwd,\n\u001b[0;32m    563\u001b[0m     reset_hooks_end\u001b[38;5;241m=\u001b[39mreset_hooks_end,\n\u001b[0;32m    564\u001b[0m     clear_contexts\u001b[38;5;241m=\u001b[39mclear_contexts,\n\u001b[0;32m    565\u001b[0m ):\n\u001b[1;32m--> 566\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39mmodel_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[0;32m    568\u001b[0m         model_out\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:573\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[1;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    569\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m    570\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[0;32m    571\u001b[0m         )\n\u001b[1;32m--> 573\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[0;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[0;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\transformer_lens\\components\\transformer_block.py:160\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[0;32m    153\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[0;32m    154\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[0;32m    156\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1_post(attn_out)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:208\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[1;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mpositional_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrotary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    206\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_rot_q(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_rotary(q, kv_cache_pos_offset, attention_mask))\n\u001b[0;32m    207\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_rot_k(\n\u001b[1;32m--> 208\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_rotary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     )  \u001b[38;5;66;03m# keys are cached so no offset\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [torch\u001b[38;5;241m.\u001b[39mfloat32, torch\u001b[38;5;241m.\u001b[39mfloat64]:\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# If using 16 bits, increase the precision to avoid numerical instabilities\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dialignment\\lib\\site-packages\\transformer_lens\\components\\abstract_attention.py:539\u001b[0m, in \u001b[0;36mAbstractAttention.apply_rotary\u001b[1;34m(self, x, past_kv_pos_offset, attention_mask)\u001b[0m\n\u001b[0;32m    536\u001b[0m     mask_rotary_sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_sin[offset_position_ids, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m    537\u001b[0m     x_rotated \u001b[38;5;241m=\u001b[39m x_rot \u001b[38;5;241m*\u001b[39m mask_rotary_cos \u001b[38;5;241m+\u001b[39m x_flip \u001b[38;5;241m*\u001b[39m mask_rotary_sin\n\u001b[1;32m--> 539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_rotated\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_pass\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_samples = 64\n",
    "batch_size = 32\n",
    "n_inst_test = 8\n",
    "tokenizer = functools.partial(tokenize, model=model)\n",
    "harmful_mean_act = sample_mean_activation(model, tokenizer, harmful_inst_train[:n_samples], batch_size)\n",
    "harmless_mean_act = sample_mean_activation(model, tokenizer, harmless_inst_train[:n_samples], batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "73061eb95f903c9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-27T00:37:05.603521500Z",
     "start_time": "2024-10-27T00:21:36.464117Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,   8144,    264,   2068,    430,    649,  17524,\n",
      "           1139,    264,   9966,   4009, 128009]]), tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,  21103,    264,  99197,   2613,    430,    649,\n",
      "          14397,   3932,   1139,   7231,   3201,    872,   5982,  16792, 128009]]), tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,   4110,    264,   3997,    430,  39990,  27052,\n",
      "            323,   3709,   3695,   9349,   2403,  23413,   5315, 128009]]), tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,   8144,    264,  11630,    389,   1268,    311,\n",
      "           1977,    264,  13054,     11,   2737,    279,  74281,    315,   7384,\n",
      "            323,    279,  14956,    315,    279,   3756, 128009]]), tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,   8144,    264,  27903,   6661,    311,    264,\n",
      "          23413,   1912,     11,   3339,   1124,   2733,  20451,    304,    872,\n",
      "           1866,   4029, 128009]]), tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,  21076,    459,  12384,    430,  56978,    323,\n",
      "          11811,  20134,   7931,    369,  40761, 128009]]), tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,  21076,    264,   2068,    430,    649,  31818,\n",
      "           4868,  11193,    323,   2680,  27285,    828, 128009]]), tensor([[128000, 128006,   9125, 128007,    271,  38766,   1303,  33025,   2696,\n",
      "             25,   6790,    220,   2366,     18,    198,  15724,   2696,     25,\n",
      "            220,   1627,   5020,    220,   2366,     19,    271, 128009, 128006,\n",
      "            882, 128007,    271,    644,   1257,   4423,   1268,    311,   5379,\n",
      "            264,  16806,   9977, 128009]])]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [48], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m refusal_dir_bylayer \u001b[38;5;241m=\u001b[39m find_activation_dir(harmful_mean_act, harmless_mean_act)\n\u001b[1;32m----> 2\u001b[0m intervention_gens, baseline_gens \u001b[38;5;241m=\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection_ablation_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefusal_dir_bylayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mharmful_inst_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43mn_inst_test\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirection_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m14\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [41], line 8\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(model, tokenizer, hook, intervention_direction, baseline_prompts, direction_layer)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m     fwd_hooks \u001b[38;5;241m=\u001b[39m [(utils\u001b[38;5;241m.\u001b[39mget_act_name(act_name, l), functools\u001b[38;5;241m.\u001b[39mpartial(hook, direction\u001b[38;5;241m=\u001b[39mintervention_direction[direction_layer])) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m intervention_layers \u001b[38;5;28;01mfor\u001b[39;00m act_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresid_pre\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m----> 8\u001b[0m intervention_generations \u001b[38;5;241m=\u001b[39m \u001b[43mget_generations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline_prompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfwd_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfwd_hooks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m baseline_generations \u001b[38;5;241m=\u001b[39m get_generations(model, baseline_prompts, tokenizer, fwd_hooks\u001b[38;5;241m=\u001b[39m[])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(baseline_prompts)):\n",
      "Cell \u001b[1;32mIn [43], line 32\u001b[0m, in \u001b[0;36mget_generations\u001b[1;34m(model, instructions, tokenize_instructions_fn, fwd_hooks, max_tokens_generated, batch_size)\u001b[0m\n\u001b[0;32m     30\u001b[0m raw_toks \u001b[38;5;241m=\u001b[39m [tokenize_instructions_fn(instructions\u001b[38;5;241m=\u001b[39minstruction) \u001b[38;5;28;01mfor\u001b[39;00m instruction \u001b[38;5;129;01min\u001b[39;00m instructions]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(raw_toks)\n\u001b[1;32m---> 32\u001b[0m all_toks \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_toks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(instructions), batch_size)):\n\u001b[0;32m     36\u001b[0m     generation \u001b[38;5;241m=\u001b[39m _generate_with_hooks(\n\u001b[0;32m     37\u001b[0m         model,\n\u001b[0;32m     38\u001b[0m         all_toks[i:i\u001b[38;5;241m+\u001b[39mbatch_size],\n\u001b[0;32m     39\u001b[0m         max_tokens_generated\u001b[38;5;241m=\u001b[39mmax_tokens_generated,\n\u001b[0;32m     40\u001b[0m         fwd_hooks\u001b[38;5;241m=\u001b[39mfwd_hooks,\n\u001b[0;32m     41\u001b[0m     )\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "refusal_dir_bylayer = find_activation_dir(harmful_mean_act, harmless_mean_act)\n",
    "intervention_gens, baseline_gens = run_experiment(model, tokenizer, direction_ablation_hook, refusal_dir_bylayer, harmful_inst_test[:n_inst_test], direction_layer=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce07690a4e84f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
